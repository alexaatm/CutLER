#!/usr/bin/env python
# Copyright (c) Meta Platforms, Inc. and affiliates.

import os
import json
import tqdm
import torch
import datetime
import argparse
import pycocotools.mask as cocomask
from detectron2.utils.file_io import PathManager

INFO = {
    # "description": "ImageNet-1K: Self-train",
    "url": "",
    "version": "1.0",
    "year": 2023,
    # "contributor": "Xudong Wang",
    "date_created": datetime.datetime.utcnow().isoformat(' ')
}

LICENSES = [
    {
        "id": 1,
        "name": "Apache License",
        "url": "https://github.com/facebookresearch/CutLER/blob/main/LICENSE"
    }
]

CATEGORIES = [
    {
        'id': 1,
        'name': 'fg',
        'supercategory': 'fg',
    },
]

new_dict_filtered = {
    "info": INFO,
    "licenses": LICENSES,
    "categories": CATEGORIES,
    "images": [],
    "annotations": []
}

category_info = {
    "is_crowd": 0,
    "id": 1
}

if __name__ == "__main__":
    # load model arguments
    parser = argparse.ArgumentParser(description='Generate json file from predictions file (no merging)')
    parser.add_argument('--new-pred', type=str, 
                        default='output/inference/coco_instances_results.json',
                        help='Path to model predictions')
    parser.add_argument('--cutler-ann', type=str, 
                        default='DETECTRON2_DATASETS/imagenet/annotations/cutler_imagenet1k_train.json',
                        help='Path to annotations in cutler format (like maskcut cutler)')
    parser.add_argument('--save-path', type=str,
                        default='DETECTRON2_DATASETS/imagenet/annotations/cutler_imagenet1k_train_r1.json',
                        help='Path to save the generated annotation file')
    parser.add_argument('--threshold', type=float, default=0.7,
                        help='Confidence score thresholds')
    args = parser.parse_args()

    # load model predictions
    new_pred = args.new_pred
    with PathManager.open(new_pred, "r") as f:
        predictions = json.load(f)

    # filter out low-confidence model predictions
    THRESHOLD = args.threshold
    pred_image_to_anns = {}
    for id, ann in enumerate(predictions):
        confidence_score = ann['score']
        if confidence_score >= THRESHOLD:
            if ann['image_id'] in pred_image_to_anns:
                pred_image_to_anns[ann['image_id']].append(ann)
            else:
                pred_image_to_anns[ann['image_id']] = [ann]

    # load pseudo-masks used by the previous round (or generated by cutler maskcut dictionary)
    pseudo_ann_dict = json.load(open(args.cutler_ann))
    pseudo_image_list = pseudo_ann_dict['images']
    pseudo_annotations = pseudo_ann_dict['annotations']

    pseudo_image_to_anns = {}
    for id, ann in enumerate(pseudo_annotations):
        if ann['image_id'] in pseudo_image_to_anns:
            pseudo_image_to_anns[ann['image_id']].append(ann)
        else:
            pseudo_image_to_anns[ann['image_id']] = [ann]

    final_anns = []

    # traverse all annotations based on cutler_ann ids
    for k, anns_pseudo in tqdm.tqdm(pseudo_image_to_anns.items()):
        try:
            anns_pred = pred_image_to_anns[k]
        except:
            continue
        final_anns += anns_pred

    # for the rest of ids not present in cutler_ann, add them too
    for key in pred_image_to_anns:
        if key in pseudo_image_to_anns:
            continue
        else:
            final_anns += pred_image_to_anns[key]

    # re-generate annotation id
    ann_id = 1
    for ann in final_anns:
        ann['id'] = ann_id
        ann['area'] = ann['bbox'][-1] * ann['bbox'][-2]
        ann['iscrowd'] = 0
        ann['width'] = ann['segmentation']['size'][0]
        ann['height'] = ann['segmentation']['size'][1]
        ann_id += 1

    new_dict_filtered['images'] = pseudo_image_list
    new_dict_filtered['annotations'] = final_anns

    # save annotation file
    # save_path = os.path.join(args.save_path, "cutler_imagenet1k_train_r{}.json".format(args.n_rounds))
    json.dump(new_dict_filtered, open(args.save_path, 'w'))
    print("Done: {} images; {} anns.".format(len(new_dict_filtered['images']), len(new_dict_filtered['annotations'])))