{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tqdm\n",
    "import torch\n",
    "import datetime\n",
    "import argparse\n",
    "import pycocotools.mask as cocomask\n",
    "from detectron2.utils.file_io import PathManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFO = {\n",
    "    \"description\": \"ImageNet-1K: Self-train\",\n",
    "    \"url\": \"\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"year\": 2022,\n",
    "    \"contributor\": \"Xudong Wang\",\n",
    "    \"date_created\": datetime.datetime.utcnow().isoformat(' ')\n",
    "}\n",
    "\n",
    "LICENSES = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"name\": \"Apache License\",\n",
    "        \"url\": \"https://github.com/facebookresearch/CutLER/blob/main/LICENSE\"\n",
    "    }\n",
    "]\n",
    "\n",
    "CATEGORIES = [\n",
    "    {\n",
    "        'id': 1,\n",
    "        'name': 'fg',\n",
    "        'supercategory': 'fg',\n",
    "    },\n",
    "]\n",
    "\n",
    "new_dict_filtered = {\n",
    "    \"info\": INFO,\n",
    "    \"licenses\": LICENSES,\n",
    "    \"categories\": CATEGORIES,\n",
    "    \"images\": [],\n",
    "    \"annotations\": []\n",
    "}\n",
    "\n",
    "category_info = {\n",
    "    \"is_crowd\": 0,\n",
    "    \"id\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmToRLE(segm, h, w):\n",
    "    if isinstance(segm, list):\n",
    "        # polygon -- a single object might consist of multiple parts\n",
    "        # we merge all parts into one mask rle code\n",
    "        rles = cocomask.frPyObjects(segm, h, w)\n",
    "        rle = cocomask.merge(rles)\n",
    "    elif isinstance(segm[\"counts\"], list):\n",
    "        # uncompressed RLE\n",
    "        rle = cocomask.frPyObjects(segm, h, w)\n",
    "    else:\n",
    "        # rle\n",
    "        rle = segm\n",
    "    return rle\n",
    "\n",
    "def rle2mask(rle, height, width):\n",
    "    if \"counts\" in rle and isinstance(rle[\"counts\"], list):\n",
    "        # if compact RLE, ignore this conversion\n",
    "        # Magic RLE format handling painfully discovered by looking at the\n",
    "        # COCO API showAnns function.\n",
    "        rle = cocomask.frPyObjects(rle, height, width)\n",
    "    mask = cocomask.decode(rle)\n",
    "    return mask\n",
    "\n",
    "def cocosegm2mask(segm, h, w):\n",
    "    rle = segmToRLE(segm, h, w)\n",
    "    mask = rle2mask(rle, h, w)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "# load model arguments\n",
    "    # parser = argparse.ArgumentParser(description='Generate labelmaps from json files')\n",
    "    # parser.add_argument('--ann', type=str, \n",
    "    #                     default='DETECTRON2_DATASETS/carotid-mini/annotations/imagenet_train_fixsize480_tau0.15_N3.json',\n",
    "    #                     help='Path to maskcut annotation or model predictions')\n",
    "    # parser.add_argument('--dataset', type=str,    \n",
    "    #                       default='DETECTRON2_DATASETS/carotid-mini/images',\n",
    "    #                     help='Path to the dataset')\n",
    "    # parser.add_argument('--save_path', type=str,\n",
    "    #                     default='DETECTRON2_DATASETS/carotid-mini/labelmaps',\n",
    "    #                     help='Path to save the generated labelmaps')\n",
    "    # parser.add_argument('--threshold', type=float, default=0.5,\n",
    "    #                     help='Confidence score thresholds')\n",
    "    # args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECTRON2_DATASETS=\"/home/guests/oleksandra_tmenova/test/project/thesis-codebase/data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ann_path = DETECTRON2_DATASETS+'/carotid-mini/annotations/imagenet_train_fixsize480_tau0.15_N3.json'\n",
    "ann_path =\"/home/guests/oleksandra_tmenova/test/project/thesis-codebase/data/carotid-mini/annotations/imagenet_train_fixsize480_tau0.15_N3.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = DETECTRON2_DATASETS + \"/carotid-mini/labelmaps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/guests/oleksandra_tmenova/test/project/thesis-codebase/data/carotid-mini/labelmaps'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = DETECTRON2_DATASETS + '/carotid-mini/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load annotations\n",
    "# ann_dict = json.load(open(ann_path))\n",
    "with PathManager.open(ann_path, \"r\") as f:\n",
    "    ann_dict = json.load(f)\n",
    "image_list = ann_dict['images']\n",
    "annotations = ann_dict['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'file_name': 'train/img0001.jpg',\n",
       " 'width': 256,\n",
       " 'height': 256,\n",
       " 'date_captured': '2023-08-29 11:47:27.705046',\n",
       " 'license': 1,\n",
       " 'coco_url': '',\n",
       " 'flickr_url': ''}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group annotations by images in a new dictionary\n",
    "image_to_anns = {}\n",
    "for id, ann in enumerate(annotations):\n",
    "    if ann['image_id'] in image_to_anns:\n",
    "        image_to_anns[ann['image_id']].append(ann)\n",
    "    else:\n",
    "        image_to_anns[ann['image_id']] = [ann]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'image_id': 1,\n",
       "  'category_id': 1,\n",
       "  'iscrowd': 0,\n",
       "  'area': 13939,\n",
       "  'bbox': [7.0, 38.0, 186.0, 151.0],\n",
       "  'segmentation': {'size': [256, 256],\n",
       "   'counts': 'ok11b02e62UI4g6HnH;5Nj6GQI?2Kl6h0N1O10N1001OL211003FnN`IR1`6QO]IP1a6QO_Io0b66iNfNjK\\\\1T4dNlK\\\\1T4eNkK\\\\1T4dNkK]1U4cNiK`1V4aN[K2Aa1T5]NYK4B`1U5\\\\NXK6@a1X5YNVKU2g4kMWKX2h4iMVKX2j4hMUKZ2j4fMUK\\\\2IaM<1R42iKa2H\\\\M91HO[43gKNNh2OWM24OL[43fKU3OhL[4^3fKbLZ4^3fKcLV4`3jKbLS4_3mKaLS4_3mK`LT4_3701O0O1000O101O1O000O0100O10O100001O000O1O2N1O1O10O01K500N2O1O100N20O100000O1000000000000O1000000000O100000N2N1100O2N10000O1NUOUKkM0g0j4^1[KaNe4^1]KaNb4_1_K`Na4a1_K_N^4d1aK]N_4c1aK\\\\N_4d1bKXNb4g1_KYNa4f1`K[N_4e1aK\\\\N^4c1cKaNY4^1iKaNW4_1iKaNW4_1iKaNX4^1iK`NZ4^1hK^NZ4b1fKWN@J0Mj4R2gKVN`4i1aKRN@No4P2aKRNAMn4P2bKSNc4i1jJTNe02b4i1`KXN`4g1]KVN]O3V5h1kJVN<6i4d1kJVN:9j4a1kJXN:8i4a1nJVN9:h4_1QKWN6:i4_1PKXN79i4`1oJWN98g4b1PKUN:6DIR5l1PKTN;6i4f1lJTN;5j4f1lJUN:3CLW5l1mJTN93DMU5l1^KTN\\\\O0Z5l1YKUNi4j1XKUNh4j1h000O10mIWNn5j1QJWNo5h1RJXNm5i15O1N2O001O1O000100O100O100O100O2O0O1O10O1bNmIn0T6lNmIL0V1T6lNnIK20K30d01_OV6M[Jc0A_OT6N[J;^OH3NU6N^J8[OFO430P74QILO0P73SILM0R73QIMM0R72RINMOS71PIOONS71oH1d700O100000_e?'},\n",
       "  'width': 256,\n",
       "  'height': 256},\n",
       " {'id': 2,\n",
       "  'image_id': 1,\n",
       "  'category_id': 1,\n",
       "  'iscrowd': 0,\n",
       "  'area': 8231,\n",
       "  'bbox': [0.0, 0.0, 256.0, 70.0],\n",
       "  'segmentation': {'size': [256, 256],\n",
       "   'counts': '0V2j500000000000000O10000O100000000000000000000000000000000000000O100001O00001OO100O10000000000O10000001O00O10000000000O1O1N2N2N200O1N2O1O1O1000000O100000000000000O100]OcIC]6<hI_OY6`0jI^OV6a0lI^OT6`0nI@R6`0nI_OS6a0mI_OS6?oI@R6?oIAQ6?oIAQ6?oIAQ6?oIAQ6?oIAQ6>PJBP6>PJBP6>PJBP6>PJBP6>PJAQ6?oIAQ6?oIAQ6?oIAQ6?oIAQ6?oIAQ69bIB=5Q69VJEk5:VJFj5:WJDj5<WJBj5>l00000O100000000000000000000000000001O000000000000000000000000000000000000O10000000000O10000001O000000000000001O0000000000001O0000O10000000000O100000000000000001O00000cHBX7>gHDX78gHG12W77hHG21V78hHG22U77iHG31T79oHGQ79oHGQ79oHHP79oHGQ73iHN6OQ73jHM41R72kHM22R71lHM22R71lHM13S7OmHNO5S7MnHNN6T7LnHNM6V7KnH:R7FnH6LHV71nH8MHS70PI6OJQ7OQI6OKP7NRI4JK53o6NRI4JK53o6NRI41Nm6NRI41Mn6OQI41Mn6OPI51Mo6NPI51Mo6NPI51Mo6NPI51Mo6NPI51Mo6NPI42Nn6NPI42Nn6NPI42Nn6NoH53Mn6NoH53Mn6NnH64Ln6NnH73Ko6NnH73Ko6NnH73Ko6NoH62Lo6NoH62Lo6NoH62Lo6NoH62Lo6NoH62Lo6NoH52On6LPI52On6LPI52On6LPI53Mn6NPI42Nn6NPI41Oo6MoH52On6LPI52No6MoH52No6MoH52No6MoH52No6MoH52No6MoH52No6MoH52No6MoH52MP7NnH52MP7'},\n",
       "  'width': 256,\n",
       "  'height': 256}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_to_anns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_labelmaps = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masks2labelmap(masks: list, h: int, w: int):\n",
    "    # print(len(masks))\n",
    "    labelmap = np.zeros((h, w), dtype=int) #Check if order h, w is correct\n",
    "    label = 1 #start from 1, to leave 0 be a background index in the labelmap\n",
    "    # n_0s = 0\n",
    "    # n_1s = 0\n",
    "    for mask in masks:\n",
    "        # n_0s = n_0s + (mask==0).sum()\n",
    "        # n_1s = n_1s + (mask==1).sum()\n",
    "        # print(mask.shape, \"0s:\", (mask==0).sum(),\"1s:\", (mask==1).sum())\n",
    "        labelmap[mask==1] = label\n",
    "        label = label + 1\n",
    "    print(\"Labelmap: 0s:\", (labelmap==0).sum(),\"1s:\", (labelmap==1).sum(), \"2s:\", (labelmap==2).sum())\n",
    "    return labelmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1/18 [00:00<00:00, 246.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256) 0s: 51597 1s: 13939\n",
      "(256, 256) 0s: 57305 1s: 8231\n",
      "Labelmap: 0s: 43366 1s: 13939 2s: 8231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for k, anns in tqdm.tqdm(image_to_anns.items()):\n",
    "    if k>1:\n",
    "        break\n",
    "    # print(k)\n",
    "    # get a list of binary masks\n",
    "    masks = []\n",
    "    for ann in anns:\n",
    "        segm = ann['segmentation']\n",
    "        mask = cocosegm2mask(segm, segm['size'][0], segm['size'][1])\n",
    "        masks.append(mask)\n",
    "\n",
    "    # since anns are grouped per image, can get h,w, name from any ann in the list\n",
    "    h = anns[0]['height']\n",
    "    w = anns[0]['width']\n",
    "    # TODO: figure out a better way to get the actual filename of th eimage (stored in image_list)\n",
    "    # E.g. can build the original im_ann dictionary using image names, not ids\n",
    "    image_id = anns[0]['image_id'] \n",
    "    \n",
    "\n",
    "    # generate labelmaps\n",
    "    labelmap = masks2labelmap(masks, h, w)\n",
    "    image_to_labelmaps[k] = labelmap\n",
    "\n",
    "    # save labelmap\n",
    "    output_file = save_path + f'/{image_id}.png'\n",
    "    # Image.fromarray(labelmap).save(output_file)\n",
    "    # labelmap_im = Image.fromarray(labelmap.astype(np.uint8)).convert('L')\n",
    "    labelmap_im = Image.fromarray(np.uint8(labelmap*255)).convert('L')\n",
    "    # print(labelmap_im)\n",
    "    labelmap_im.save(output_file)\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = image_to_labelmaps[1]\n",
    "\n",
    "# values = np.unique(pred.ravel())\n",
    "# im = plt.imshow(pred)\n",
    "# plt.axis(False)\n",
    "# colors = [ im.cmap(im.norm(value)) for value in values]\n",
    "# # create a patch (proxy artist) for every color \n",
    "# patches = [ mpatches.Patch(color=colors[i], label=\"{l}\".format(l=values[i]) ) for i in range(len(values)) ]\n",
    "# # put those patched as legend-handles into the legend\n",
    "# plt.legend(handles=patches, bbox_to_anchor=(1., 1), loc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_to_labelmaps[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-3.8.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
